name: Scheduled Warspotting Scraper

on:
  schedule:
    - cron: '0 1 * * 1-6'     # Mondayâ€“Saturday daily run at 01:00 UTC
    - cron: '0 1 * * 0'       # Sunday full scan at 01:00 UTC
  workflow_dispatch:           # Manual trigger allowed

jobs:
  run:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.11

      - name: Install dependencies
        run: pip install pandas requests kaggle

      - name: Run scraper
        run: python automated_warspotting_scraper.py

      - name: Commit updated CSV
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add warspotting_losses.csv
          git commit -m "ðŸ”„ Auto update CSV - $(date +'%Y-%m-%d')" || echo "No changes to commit"
          git push

      - name: Prepare Kaggle dataset folder
        run: |
          mkdir -p kaggle_dataset
          cp warspotting_losses.csv kaggle_dataset/
          cat > kaggle_dataset/dataset-metadata.json <<EOF
          {
            "id": "zsoltlazar/automated-warspotting-equipment-losses",
            "title": "Automated Warspotting Equipment Losses",
            "licenses": [{"name": "CC0-1.0"}]
          }
          EOF

      - name: Upload CSV to Kaggle
        env:
          KAGGLE_USERNAME: ${{ secrets.KAGGLE_USERNAME }}
          KAGGLE_KEY: ${{ secrets.KAGGLE_KEY }}
        run: |
          kaggle datasets version -p kaggle_dataset -m "Auto update $(date +'%Y-%m-%d')" --dir-mode zip

      - name: Append CSV to Google Sheet
        env:
          GOOGLE_SERVICE_ACCOUNT_KEY: ${{ secrets.GOOGLE_SERVICE_ACCOUNT_KEY }}
        run: |
          pip install gspread pandas
          echo "$GOOGLE_SERVICE_ACCOUNT_KEY" > service_account.json
          python - <<'PYCODE'
import gspread
import pandas as pd

# === CONFIG ===
SHEET_ID = "1jtEbRTZBcHTicifxfoUMgosIKMCJm7XBaDRTFGX1p18"
CSV_PATH = "warspotting_losses.csv"
TAB_NAME = "Warspotting"
UNIQUE_COLUMN = "id"  # change if your dataset uses another unique identifier
# ===============

# Load local CSV
df_new = pd.read_csv(CSV_PATH)

# Connect to Google Sheets
gc = gspread.service_account(filename="service_account.json")
sh = gc.open_by_key(SHEET_ID)

# Try to open the worksheet
try:
    worksheet = sh.worksheet(TAB_NAME)
    existing_data = worksheet.get_all_records()
    df_existing = pd.DataFrame(existing_data)
except gspread.exceptions.WorksheetNotFound:
    worksheet = sh.add_worksheet(title=TAB_NAME, rows="1000", cols="20")
    df_existing = pd.DataFrame()

# Merge data (avoid duplicates if possible)
if not df_existing.empty and UNIQUE_COLUMN in df_existing.columns and UNIQUE_COLUMN in df_new.columns:
    df_combined = pd.concat([df_existing, df_new]).drop_duplicates(subset=[UNIQUE_COLUMN], keep="last")
else:
    df_combined = pd.concat([df_existing, df_new])

# Update worksheet
worksheet.clear()
worksheet.update([df_combined.columns.values.tolist()] + df_combined.values.tolist())

print(f"âœ… Uploaded {len(df_combined)} total rows to '{TAB_NAME}' in Google Sheet.")
PYCODE
